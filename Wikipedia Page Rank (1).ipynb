{"cells":[{"cell_type":"markdown","source":["# Wikipedia Page Rank\n\nPageRank is an algorithm that is used to determine the importance of a webpage or a set of webpages. It was developed by Larry Page and Sergey Brin, the founders of Google, as a way to rank webpages in the search engine's results. The basic idea behind PageRank is that a webpage is important if it is linked to by many other important webpages.\n\nThe algorithm works by treating each webpage as a node in a directed graph, with edges representing links between webpages. The importance of a webpage (its PageRank) is then computed based on the importance of the webpages that link to it. The algorithm uses a recursive formula to iteratively calculate the PageRank of each webpage, until a stable rank is reached.\n\n\n\nThe provided code is an implementation of the PageRank algorithm which is a method used to determine the importance or relevance of a page in a website based on the number and quality of links that point to it. The algorithm is typically used to rank web pages in search engine results."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"49b1ee56-9657-4283-87fa-491295fd3ab2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Part 0: Imports"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6f1ca151-3c59-47a8-b0ad-433c8fd3ddce","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pandas as pd\nimport re"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"000ae955-cd3b-4a52-9e0c-978241c38d5c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.types import ArrayType, StringType,LongType\nfrom pyspark.sql.functions import size, explode, collect_list \nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"10865609-2787-4474-900b-54e4dd830765","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7ae6143a-d173-4019-861b-e9955817c173","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 1: Get the data \n\n- read a parquet file and create a DataFrame\n- count the total number of rows in the DataFrame\n- take a random sample of the DataFrame with a fraction of 0.001 and random seed 0, and cache it in memory"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0acb0187-39c5-4fad-8e2e-e3e57352967c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["wikipediaDF=spark.read.parquet(\"dbfs:/databricks-datasets/wikipedia-datasets/data-001/en_wikipedia/articles-only-parquet\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"29455663-e769-4c76-a3b0-370d20b553a8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Count the total rows of the DF\nN=wikipediaDF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e16e48be-33f7-47c7-8265-a94866829c01","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["PartialWikipediaDF=wikipediaDF.sample(fraction=0.0001,seed=0).cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8f1bd9c8-7f2f-4780-b338-8e55fbd947a1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#display(PartialWikipediaDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"01e0bba7-8708-4e6e-b3b9-b4e00e5adf12","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 2: Parse the link in the data frame\nUsing a udf(user defined function) parse the text field from each record"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"45dae667-680f-4454-ae07-33f503f14f8d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### (2a) define the function and the udf"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"59c29a9a-f2f1-4773-bbdc-ce0b625ab87e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# function which parses the text field from each record, and extracts the outgoing links.\ndef parse_links(document_body):\n  # Find all strings that match the pattern [[...]]\n  data = re.findall(r'\\[\\[(.+?)\\]\\]',document_body)\n  \n  # If there are any matches\n  if (len(data) > 0):\n    # convert all the matches to lowercase\n    links = [s.lower() for s in data]\n  else:\n    # if there are no matches, return an empty list\n    links = []\n  return links\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"77276afc-1f7c-4a23-860c-c923682a882e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# define the udf for parsing a link\nparse_links_udf = udf(parse_links,ArrayType(StringType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"91652eea-ca38-4c8d-9291-7ad0f60fd66f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["tolower_udf= udf(lambda x: x.lower())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9c9ce40-6272-43bc-b370-eb7f6ee6ecce","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## (2b) create a title dataframe\ntitle_idDF is created by selecting the lowercase title and id fields from wikipediaDF. And it's been converted to pandas dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b48ecaba-f52d-4b34-81db-d1aaccfc2bf8","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["title_idDF=wikipediaDF.select(lower(\"title\").alias(\"title\"),\"id\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5c68b849-db6c-4747-9e48-c3995988ce80","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#convert the spark df to pandas\ntitle_idPDF=title_idDF.toPandas()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"50b3e884-df1f-4e8d-ad61-9dbea9f6eea0","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## (2c) create a dataframe with the parsed link\nTempForwardDF is created by selecting the title, id, and links (using parse_links_udf function on text field) fields from PartialWikipediaDF."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fc4ac4bd-b3fc-4347-b68b-30448f26378b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["TempForwardDF=PartialWikipediaDF.select(\"title\",\"id\",parse_links_udf(\"text\").alias(\"links\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6df730cf-18f6-419b-be9e-0e049841c7b5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#display(TempForwardDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5ec5da9-69fd-45ec-b476-7cc02030ff1b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 3: create a Forward data frame \nCreate a forward df with the forwarding link of each node"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"17bc42db-80ef-470d-9dd0-b953012cf43d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## (3a)  convert titles of the link into their ids\nFunction called titles2id is defined, which takes in a list of links and a pandas dataframe with titles and ids, and returns a list of ids corresponding to the links that are present in the pandas dataframe. This function is then wrapped in a udf called titles2id_UDF, which is used to create a new DataFrame called ForwardDF."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b67abdaf-0afc-4908-a5cb-82a089d99a43","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# function that search and replace the links with the ids of the corresponding documents, to handle just numbers\ndef titles2id(links,titleidPDF):\n  # df with titles and ids\n  data_titles=titleidPDF\n  # if row has outgoing links\n  if (len(links)>0):\n    # check if a title is in the links and append his id to a list \n    ids=data_titles[data_titles.title.isin(links)].id.to_list()\n  else:\n    ids=[]\n  return list(set(ids))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9fad811e-b47e-4c4f-bbf5-f4528f372393","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["titles2id_UDF=udf(lambda x: titles2id(x,title_idPDF),ArrayType(LongType(),False))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a616e871-43fe-4a51-a0ad-f56b52855e4b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## (3b) Create the forward df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b72b0e7d-2b8a-4f27-8456-d96db04aa691","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["ForwardDF=TempForwardDF.select(\"id\",titles2id_UDF(\"links\").alias(\"links\"),size(\"links\").alias(\"counter\")).cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5a7de5e1-c880-47b3-8b33-369a0d436600","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#display(ForwardDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da2335bf-8073-470d-98d4-45c34fb43b80","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 4: Create the reverse dataframe, and the page rank dataframe \nCreate the reverse data frame that will be used lately to compute the page rank algorithm.\n\nThis dataframe will have an id(the id of the node), the links that are pointing to the node, and the counters of the links that point to the node."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"03ea5461-5f25-475d-b065-45c6bb226f01","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## (4a) create the df for the outgoing links\nFor each link select how many links are outgoing from him"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0caad556-e024-4d7f-81f4-89669eba2516","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["OutgoingsLinksCountersDF=ForwardDF.select(\"id\",\"counter\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d9f97107-c3c0-4cbd-a3d5-b5f5249f9942","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#display(OutgoingsLinksCountersDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3e55fd7d-2303-419f-abe2-337b72f93469","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## (4b) Create a temporal reverse link dataframe\n\nThe select() function is used to select specific columns from the \"ForwardDF\" DataFrame, and in this case, it's selecting the \"id\" column and the \"counter\" column. \n\nThen it's using the explode() function on the \"links\" column and creating a new column called \"t_link\". The explode() function will create a new row for each element in the \"links\" column, so if the \"links\" column contains a list of n elements, the resulting DataFrame will have n rows, each with a copy of the \"id\" and \"counter\" columns and a single element from the \"links\" column in the \"t_link\" column."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c62eb634-597c-4390-8676-f7003e587af4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["TemporalReverseLinks=ForwardDF.select(\"id\",explode(\"links\").alias(\"t_link\"),\"counter\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"59dca80a-2a3a-4118-b079-075aade7764b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#display(TemporalReverseLinks)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"af5418c5-1a1a-40d1-8e1f-9c9694354b8d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## (4c) Create the reverse df\nreverseDF is grouping the TemporalReverseLinks DataFrame by the \"t_link\" column, then using the groupBy method to perform two aggregation operations:\n\n- Using collect_list() function to create a new column \"Links\" which contains a list of all the values of \"id\" column in the group.\n\n- Using collect_list() function to create a new column \"counters\" which contains a list of all the values of \"counter\" column in the group.\n  then it renaming the \"t_link\" column to \"id\" using withColumnRenamed() function.\n  And it's caching the ReverseDF Dataframe for faster access in future operations.\n  It's important to note that without the context of the rest of the program and the structure of the TemporalReverseLinks DataFrame, it's hard to say exactly what this line of code does and what the final DataFrame will look like."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3f7a5bbb-2423-4205-ae9a-f2a820e43eab","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["ReverseDF=TemporalReverseLinks.groupBy(\"t_link\").agg(collect_list (\"id\").alias(\"Links\"),collect_list(\"counter\").alias(\"counters\")).withColumnRenamed(\"t_link\",\"id\").cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7ddc69e7-0948-4a6e-a832-ea52bb8212bb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#display(ReverseDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"289f1f6f-925f-45e2-80c4-cd0852e257a7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ReverseDF.printSchema()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6ff0212c-696a-45e2-9b18-e8a2394d6871","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## (4d) Create the page rank df\nCreate a DataFrame with the id and Page Rank initialized with 0.85/N and convert it to pandas dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d25aaa89-da72-4a2e-aa96-d2533bf94513","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# add column PR\npageRankDF=ReverseDF.select(\"id\")\npageRankPDF=pageRankDF.toPandas()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d66dbf71-2d5b-43b0-91a0-8ec33278f99b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pageRankDF=pageRankDF.withColumn(\"PR\",lit(0.85/N))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ce982f9e-7b82-443f-a1cb-f7023c1b1b99","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pageRankPDF[\"PR\"]=0.85/N"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6d1621a2-9d74-49ac-bd88-92cdba0f5315","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pageRankDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c3d079d-6d40-4656-b71d-155750e069a2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#display(pageRankPDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"116572ae-1d3b-4128-9972-1c31b50ec35b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Part 5: Compute the algorithm\n\nFinally, the PageRank algorithm is implemented by iterating over the ReverseDF, updating the Page Rank values of each page based on the links and counters, and checking for convergence of the algorithm."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0f9596bc-bf2b-4980-a161-eb20216c96a5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## (5a) Define the function for calculating the new page rank\nDefine a function that calculates the new Page Rank for a given document"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6f481acf-ce8d-4421-ae34-1c96bf4558d2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\ndef new_pagerank(links, current_pr, counters):\n  n_pr = 0;\n  # for each incoming link to the page calculate the pagerank\n  # zip the links and counters to get them both in the loop\n  for l, c in zip(links, counters):\n    \n    \n    # get current_pr of the link l\n    try:\n      current_link_pr=current_pr[current_pr['id']==l].PR.item()\n      \n    # this except is used in case that some links doesn't have a page rank\n    # this can occurr when using a sample data frame\n    except:\n      current_link_pr=0.85/N\n        \n    # update the new Page Rank by adding the contribution of this link\n    n_pr += current_link_pr/c\n  new_pr = 0.85/N+0.15*n_pr\n  return new_pr\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9480bf63-2c3a-4633-9875-c89d1fa92518","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## (5b) Define the function for checking if  is converged\nDefine a function that checks if the Page Rank has converged,checking if the relative error between two values (current and previous) is less than or equal to a certain threshold (0.00001)."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"33eeabe2-beab-46d4-ad03-cf5b193a9c70","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def converged(current,previous):\n    relative_error = abs(current - previous) / abs(previous)\n    return relative_error <= 0.00001\n    \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cdfa5b97-8381-4d52-9e05-5aef2090b251","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## (5c) Compute the algorithm \n It uses a while loop to iterate until the Page Rank has converged or the maximum number of iterations (20) is reached. \n \n The loop starts by calculating the new Page Rank of each document using the new_pagerank function. \n \n This function takes in the links and counters of a document and the current Page Rank DataFrame, then calculates the new Page Rank by adding the contribution of each incoming link.\n \n After that, it checks for convergence by comparing the new and previous Page Rank DataFrames. If all the documents have converged, the loop is stopped. \n \n Finally, the final Page Rank DataFrame is displayed."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ff41937b-ab61-4257-9abd-03795c559b93","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# create a UDF that applies the new_pagerank function to the DataFrame\nnew_pagerank_udf = udf(lambda x,y: new_pagerank(x,pageRankPDF,y), DoubleType())  \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b205b183-6564-4b2d-996c-bcc32e86497d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# create a DataFrame to store the previous Page Rank(used for checking if is converged or not)\nPreviousPageRankDF=pageRankDF\ncount=0;\nflag=True\n# iterate until the Page Rank has converged or the maximum number of iterations is reached\nwhile ((flag==True) & (count<20)):\n    # calculate the new Page Rank\n    NewPageRankDF=ReverseDF.select(\n        ReverseDF[\"id\"],\n        new_pagerank_udf(ReverseDF[\"links\"],ReverseDF[\"counters\"]).alias(\"PR\"))\n    pageRankPDF=NewPageRankDF.toPandas()\n    \n    # join the new and previous Page Rank DataFrames to check for convergence\n    checkConvergenceDF=NewPageRankDF.withColumnRenamed(\"PR\",\"New_PR\").join(PreviousPageRankDF,NewPageRankDF[\"id\"] == PreviousPageRankDF[\"id\"])\n    \n    # check if the Page Rank has converged\n    checkConvergenceDF=checkConvergenceDF.withColumn(\"is_converged\",converged(checkConvergenceDF[\"New_PR\"],checkConvergenceDF[\"PR\"]))\n    # exit condition if all the rows are converged\n    if checkConvergenceDF.filter(col(\"is_converged\")).count() == checkConvergenceDF.count():\n        flag=False\n\n    # update the udf with the new pagerank pdf\n    new_pagerank_udf = udf(lambda x,y: new_pagerank(x,pageRankPDF,y), DoubleType())\n    #display(pageRankPDF)\n    \n    PreviousPageRankDF=NewPageRankDF\n    count=count+1\n    \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3c5835e2-fe31-423a-b161-95998556d72d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# display the final Page Rank DataFrame\ntitle_idPDF = title_idPDF.drop_duplicates(subset='id')\nmerged_PDF = pd.merge(pageRankPDF, title_idPDF, on='id')\nresult_PDF = merged_PDF[['title', 'id', 'PR']]\ndisplay(result_PDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cb4d4d5f-33c2-4abb-af46-2d1596aa48cd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Analysis"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6e0f1f2b-758f-4624-aeeb-c3122f0f03cc","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Links without incoming links problem\nIf a page does not have any incoming links in the PageRank algorithm, it will not be included in the calculation of the PageRank scores for other pages.\n\nThis problem can lead to inaccuracies in the PageRank scores for other pages. This is because the algorithm calculates the PageRank of a page based on the number of links that point to it. If a page does not have any incoming links, it will not be included in the calculation of the PageRank for other pages, and therefore will not contribute to the accuracy of the PageRank scores.\n\nA solution is use a try except construct to try to search the page rank of that link, and if not present assign a default value(0.85/N in this case).\nUsing this solution will give you good estimates of the page rank,but still not the most accurate because it will converge really fast(2/3 iteration for 0.0001 sample and 4/5 iteration for 0.001).\n\nIt's also worth noting that these solutions may not be completely accurate and this may not be entirely resolved. The best way to solve it is to have a large dataset with many incoming links, in this way the algorithm can be able to distribute the page rank to all the pages in the dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c0268b69-b2c8-4e5e-9a3e-f7289c531dc9","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Dangling nodes problem\nThis problem refers to the issue in the PageRank algorithm where some web pages do not have any outgoing links and therefore do not contribute to the calculation of the PageRank scores for other pages. These pages are considered \"dangling nodes\" as they do not contribute to the link structure of the network.\n\nThe problem with dangling nodes is that they can lead to inaccuracies in the PageRank scores for other pages. This is because the algorithm calculates the PageRank of a page based on the number of links that point to it. If a page does not have any outgoing links, it will not be included in the calculation of the PageRank for other pages, and will not contribute to the accuracy of the PageRank scores.\n\nThis problem can be solved using the damping factor."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2987583d-f64b-4391-bcd5-d3048466e720","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Damping factor\nThe damping factor is a probability value that is used in the PageRank algorithm to handle the problem of web pages that form a directed cycle, leading to a situation where the algorithm would never converge.\n\nThe damping factor is used to introduce a small probability that, at each step, the random surfer will \"teleport\" to a random webpage rather than following a link. This means that even if a webpage is in a cycle of pages that all link to each other, there is still a small chance that the random surfer will leave the cycle and explore other pages.\n\nThe damping factor is typically set to a value between 0 and 1, with a common value being 0.85(as in this case). This means that at each step, there is a 15% chance that the random surfer will \"teleport\" to a random webpage.\n\nA damping factor of 0 means that the random surfer never teleports to other pages and will eventually get stuck in a loop. A damping factor of 1 means that the random surfer never follows links and only teleports to other pages. \n\nIt is important to note that the damping factor value chosen will affect the result of the algorithm, and a different value might lead to different ranking of pages.\n\nIt's also worth noting that the PageRank algorithm is susceptible to manipulation by spammers. Additionally, like all algorithm, the results of PageRank algorithm can be affected by the data bias and damping factor, because spammers often use link farms (a group of web pages that all link to each other) to increase the importance of their web pages, these pages will tend to have artificially high PageRank scores."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8da56ca2-1579-44fc-8cb4-782e44fc6818","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Convergence\n\nConvergence in the context of the PageRank algorithm refers to the point at which the algorithm has iterated enough times that the page rank scores of the nodes in the network have stabilized and are not changing significantly with each iteration. \n\nThis can be determined by comparing the page rank scores of the nodes between consecutive iterations and checking if they have reached a certain level of similarity. \n\nOnce the algorithm has converged, the final page rank scores can be considered to be a good approximation of the true page rank of the nodes in the network.\n\nTo check if is converged we use a relative error, a measure of how much the PageRank values have changed between iterations. It is calculated as the absolute difference between the current PageRank values and the previous PageRank values, divided by the absolute value of the previous PageRank values."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c1e0769e-9461-4491-9800-8785e9494364","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Limitations\n\n\n* The algorithm is based on the assumption that the network graph is static, but this is not true because the web is always changing, with new pages being added and old pages being removed, one solution is re-run periodically the algorithm.\n* The algorithm is computationally intensive, could be slow with large dataset, with limited resources like in this case using databricks community, the algorithm can be too slow to run efficiently.\n* The susceptibility to manipulation by spammers is also a significant problem. Spammers can use link farms (a group of web pages that all link to each other) to increase the importance of their web pages, which can lead to inaccurate or unreliable results\n* The algorithm is based on the assumption that all webpages are equally likely to be visited, and that all links are created equal. These assumptions may not be true in reality, leading to inaccurate or unreliable results."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7361d991-94f4-4fac-b5cb-0b9ba852546d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Conclusions\nIn conclusion, the PageRank algorithm is a useful tool for determining the importance of web pages by taking into account both the number and quality of inbound links. However, it has limitations such as assuming a static network, being computationally intensive, and being susceptible to manipulation by spammers.\n\nIt is important to use the algorithm with caution and in conjunction with other methods to ensure accurate results."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7e660380-0a21-47c0-979a-d74f7e9cb175","inputWidgets":{},"title":""}}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.11","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"Wikipedia Page Rank","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":838356696754887}},"nbformat":4,"nbformat_minor":0}
